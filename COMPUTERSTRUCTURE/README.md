# 컴퓨터 구조

### 컴퓨터 구조를 왜 알아야하는가?
소프트웨어가 하드웨어와 어떻게 상호 작용하는지를 이해함으로써, 성능 최적화, 리소스 관리, 디버깅 과정에서 발생하는 문제를 더 잘 이해하고 해결할 수 있다.  

### 컴퓨터 구조는 크게 두 섹터로 볼 수 있다
1. 컴퓨터가 이해하는 정보
    - 데이터
    - 명령어
2. 컴퓨터의 핵심 부품
    - CPU
    - 메모리(주기억장치, 메인메모리)
    - 보조기억장치
    - 입출력장치

### 처음엔 간단한 정의 정도로 시작하자
1. 컴퓨터가 이해하는 정보
    - **데이터**: 컴퓨터는 `0, 1`만 이해할 수 있다. 이 0, 1을 가지고 숫자, 문자, 이미지, 동영상 같은 정적인 정보를 나타낸 것을 데이터라고 한다.  
    - **명령어**: 컴퓨터는 결국 명령어를 처리하는 기계이다.  

2. 컴퓨터의 핵심 부품
    - **CPU**; Central Processing Unit: 메모리에 저장된 명령어를 읽어 들이고, 해석하고, 실행하는 부품이다.
    - **메모리**: 현재 실행되는 프로그램의 데이터와 명령어를 저장하는 부품이다.
        - **RAM**; Random Access Memory: 휘발성 메모리로, 작업중인 파일을 한시적으로 저장한다.
        - **ROM**; Read Only Memory: 비휘발성 메모리로, 컴퓨터에 지시사항을 영구히 저장한다.
    - **보조기억장치**: USB, SD카드, SSD, 하드디스크 같이 대용량, 백업용으로 사용할 수 있는 장치이다.
    - **입출력장치**: 키보드, 모니터, 스피커 같이 컴퓨터 외부에서 컴퓨터 내부로 정보를 주고 받을 수 있는 장치이다.

### CPU를 조금 더 살펴보자
- CPU
    - **산술 논리 연산 장치**; Arithmetic & Logic Unit; ALU: 비교, 판단, 연산을 담당한다.
    - **제어 장치**; Control Unit; CU: 프로세서의 조작을 지시하는 역할을 담당한다.
    - **레지스터**: 컴퓨터의 프로세서 내에서 자료를 보관하는 아주 빠른 기억 장소이다.

### 핵심 부품이 서로 어떻게 작동하는지 알아보자
위의 네 가지 핵심 부품은 **메인보드**에서 결합된다. 메인보드에는 1. `주소 버스` 2. `데이터 버스` 3. `제어 버스` 라는 세 가지 시스템 버스(통로)가 있다. 이 시스템 버스를 통해서 각 부품들이 서로 정보를 주고 받을 수 있게 된다.  

#### Case 1. 메모리 값 읽어 들이기
1. 메모리 주소(1번지): 더하라, 3번지와 4번지를
2. 메모리 주소(2번지): 저장하라, 연산 결과를
3. 메모리 주소(3번지): 120
4. 메모리 주소(4번지): 100

*CPU는 메모리 주소 1번지에 저장된 명령어를 읽어 들이고 싶다!*   
메모리 읽기를 제어 버스를 통해, 1번지를 주소 버스를 통해 보낸다. 메모리는 그 신호를 받고 해당 정보를 데이터 버스를 통해 다시 CPU로 보낸다. CPU는 받은 정보를 레지스터에 저장해놓고 순서대로 처리한다.

#### Case 2. 메모리 값 쓰기
*CPU는 값을 쓰고 싶다!*  
레지스터에 저장된 값(220)을 데이터 버스에 통해, 5번지를 주소 버스에 통해, 메모리 쓰기를 제어 버스에 통해 보낸다. 메모리는 그 신호를 받고 5번지에 해당 값을 저장해놓는다.

## 데이터로 돌아가서
> 컴퓨터는 오직 0, 1만 이해하는데 1보다 큰 수를 어떻게 알 수 있을까?

### 0과 1로 숫자를 표현하는 방법

#### 정보 단위
0, 1을 표현하는 가장 작은 정보 단위를 `비트`라고 한다. 비트를 전구라고 본다면 전구가 꺼진 상태를 0, 전구가 켜진 상태를 1이고, 1 비트는 두 가지 정보를 담고 있다는걸 알 수 있다. n비트의 정보 단위의 수 = 2^n으로 표현할 수 있다. 프로그램은 수많은 비트로 이루어져 있지만 일반적으로 바이트, 킬로바이트, 메가바이트, 기가바이트, 테라바이트 등 더 큰 단위로 표현한다.
- 1 바이트(byte): 8 비트(bit)
- 1 킬로바이트(kB): 1000 byte
- 1 메가바이트(MB): 1000 kB
- 1 기가바이트(GB): 1000 MB
- 1 테라바이트(TB): 1000 GB  

CPU가 한번에 처리할 수 있는 정보의 크기 단위를 `워드`라고 한다.  

#### 이진법(binary)
0과 1로 숫자를 표현하는 방법이다. 숫자가 1을 넘어가는 시점에 자리올림을 하여 사용한다.
- 십진수 : 이진수
- 1 : 1
- 2 : 1 0
- 3 : 1 1
- 4 : 1 0 0
- 5 : 1 0 1
- 6 : 1 1 0
- 7 : 1 1 1
- 8 : 1 0 0 0

> 그럼 음수는 어떻게 표현할까?

어떤 수를 그보다 큰 2^n에서 뺀 값을 음수로 사용하는 `2의 보수법`을 사용한다. 쉽게 구하는 방법은 모든 0과 1을 뒤집고 1을 더하면 된다. 예를 들어, 1 1의 음수를 구한다고 할 때 0 0으로 뒤집고 1을 더해주어 0 1을 만들면 된다.  

> -1011을 표현한 0101과 십진수 5를 표현한 0101은 어떻게 구분할까?

CPU 내부엔 양수와 음수를 구분하는 플래그 레지스터가 존재한다.

> 이진법으로 표현하면 숫자가 너무 길어질 것 같은데..?

때문에 데이터를 표현할 때 십육진법도 많이 사용한다. 십육진법은 수가 15를 넘어가는 시점에 자리올림을 해서 표현한다.
- 십진수 : 십육진수
- 0 : 0
- 1 : 1
- 2 : 2
- 3 : 3
- 4 : 4
- 5 : 5
- 6 : 6
- 7 : 7
- 8 : 8
- 9 : 9
- 1 0 : A
- 1 1 : B
- 1 2 : C
- 1 3 : D
- 1 4 : E
- 1 5 : F
- 1 6 : 1 0
- 1 7 : 1 1
- ... : ...

***십진수의 1 0과 십육진수의 1 0을 어떻게 구분하지?***

1. 10(16) : 수학적 표기 방식
2. 0x10 : 코드상 표기 방식

### 0과 1로 문자를 표현하는 방법

#### 먼저 용어를 살펴보자
- 문자 집합: 컴퓨터가 이해할 수 있는 문자 모음
- 인코딩(encoding): 문자를 0과 1로 이루어진 문자 코드로 변환하는 과정
- 디코딩(decoding): 0과 1로 표현된 문자 코드를 문자로 변환하는 과정

#### 대표적인 문자 집합
ASCII 코드는 초창기 문자 집합 중 하나이다. 하나의 문자를 표현하기 위해서 8 비트가 사용되고 그 중 1 비트는 오류 검출을 위해 사용되는 parity bit이므로 실제 문자 표현에 7 비트가 사용된다. 한글을 포함한 다른 언어를 표현할 수 없다는 한계가 있다.  

> 모든 언어, 특수문자까지 통일된 문자 집합, 그리고 인코딩 방식을 사용하면 어떨까?

그렇게 생겨난게 `유니코드 문자 집합`과 `utf-8` 인코딩 방식이다. 이 유니코드는 한글, 영어, 특수 문자, 이모티콘까지 사용할 수 있어 현대 문자 표현에 중요한 위치에 있다. utf-8 인코딩은 1 byte~4 byte까지 될 수 있는 가변 길이를 갖고 있다. 이 인코딩 결과가 몇 byte가 될지는 유니코드에 부여된 값에 따라 다르다.

### 이제 소스 코드와 명령어를 보자
C++로 작성된 소스 코드를 컴퓨터는 바로 알아들을 수 없다. C++, java, python 같은 언어는 인간이 이해하기 위한 `고급 언어`에 속한다. 컴퓨터는 이 고급 언어를 알아듣기 위해 `저급 언어`로 변환시킨다. 이 저급 언어는 명렁어들로 이루어져 있고 위에서 본 이진법이나 십육진법을 사용하는 `기계어`와 그걸 인간의 이해를 위해 변환시킨 `어셈블리어`로 나뉜다.  

고급 언어를 저급 언어로 변환하는 과정은 크게 두 가지로 `컴파일`과 `인터프리트` 과정이 있다.  하나씩 살펴보자.

- 컴파일 언어: 고급 언어로 작성된 소스 코드는 컴파일러를 통해 목적 코드로 변환된다.
- 인터프리트 언어: 컴파일 언어는 소스 코드 전체를 컴파일하지만 인터프리트 언어는 인터프리터에 의해 소스 코드 한 줄씩 실행이 되기 때문에 소스 코드 전체가 저급 언어로 변환되기까지 기다릴 필요가 없다.  

이 두 언어가 흑과 백처럼 칼로 자르듯 양분되는 개념은 아니다.

> 명령어 하나하나는 어떻게 생겼을까?  

"무엇을 대상으로, 무엇을 수행하라" 구조로 일상에서 명령을 내리는 것과 크게 다르지 않다. 예를 들면, "더하라, 100과 120을" 같이 "수행할 연산, 연산에 사용될 데이터 혹은 위치" 형태를 띄고 있다. 이를 정확하게는 `"연산 코드, 오퍼랜드"` 구조라고 한다.  

#### Operand
연산에 사용될 데이터 혹은 저장된 위치라고 했지만 실제로 연산에 사용될 데이터의 저장된 위치가 더 많이 사용되어 이를 **주소 필드**라고 부르기도 한다. 연산에 사용될 데이터의 저장된 위치만을 부를 땐 **유효 주소**(effective address)라고 한다. 이 유효 주소를 찾는 방식이 여러 개가 있는데 그걸 **명령어 주소 지정 방식**(addressing modes)라고 한다.  

##### 명령어 주소 지정 방식
- 즉시 주소 지정 방식
    - 가장 간단한 형태의 주소 지정 방식으로 연산에 사용할 데이터를 오퍼랜드 필드에 직접 명시한다. 연산에 사용할 데이터의 크기가 작아질 순 있지만 빠르다는 특징을 갖고 있다.
- 직접 주소 지정 방식
    - 오퍼랜드 필드에 유효 주소를 직접적으로 명시하는 방법이다. 유효 주소를 표현할 수 있는 크기가 연산 코드만큼 줄어드는 점이 있다.
- 간접 주소 지정 방식
    - 오퍼랜드 필드에 유효 주소의 주소를 명시하는 방법이다. 앞선 방식들에 비해 속도가 느린 특징이 있다.
- 레지스터 주소 지정 방식
    - 연산에 사용할 데이터가 저장된 레지스터를 명시하는 방법이다. *메모리에 접근하는 속도보다 레지스터에 접근하는 것이 빠르다.*
- 레지스터 간접 주소 지정 방식
    - 연산에 사용할 데이터를 메모리에 저장하고 그 주소를 저장한 레지스터를 오퍼랜드 필드에 명시하는 방식이다.

> 근데 왜 데이터가 아닌 주소를 저장하는거지?

주소 명령어에서 표현할 수 있는 데이터 크기가 제한되기 때문이다.

#### 연산 코드
연산 코드의 종류와 생김새는 CPU마다 다양하다. 일반적인 기능은 아래와 같다.
1. 데이터 전송
    - MOVE: 데이터를 옮겨라
    - STORE: 메모리에 저장하라
    - LOAD(FETCH): 메모리에서 CPU로 데이터를 가져와라
    - PUSH: 스택에 데이터를 저장하라
    - POP: 스택의 최상단 데이터를 가져와라
2. 산술/논리 연산
    - ADD/SUBTRACT/MULTIPLY/DIVIDE: 사칙연산을 수행하라
    - INCREMENT/DECREMENT: 오퍼랜드에 1을 더하라/빼라
    - AND/OR/NOT
    - COMPARE: 두 개의 숫자 또는 True/False 값을 비교하라
3. 제어 흐름 변경
    - JUMP: 특정 주소로 실행 순서를 옮겨라
    - CONDITIONAL JUMP: 조건에 부합할 때 JUMP 연산을 수행하라
    - HALT: 프로그램의 실행을 멈춰라
    - CALL: 되돌아올 주소를 저장한 채 특정 주소로 실행 순서를 옮겨라
    - RETURN: CALL을 호출할 때 저장했던 주소로 돌아가라
4. 입출력 제어
    - READ(INPUT): 특정 입출력 장치로부터 데이터를 읽어라
    - WRITE(OUTPUT): 특정 입출력 장치로 데이터를 써라
    - START IO: 입출력 장치를 시작하라
    - TEST IO: 입출력 장치의 상태를 확인하라

### C언어 컴파일 과정을 살펴보자
**test.c > 전처리기 > test.i > 컴파일러 > test.s > 어셈블러 > test.o > 링커 > test.exe**

- 전처리(preprocessing) 과정: 본격적으로 컴파일하기 전에 준비 작업을 하는 것으로 외부의 라이브러리를 포함시키거나 프로그래밍의 편의를 위해 작성된 매크로를 변환하거나 컴파일할 영역을 명시하는 등의 작업을 말한다.
- 컴파일(compile) 과정: 전처리가 완료 되어도 여전히 소스 코드이기 때문에 저급 언어로 변환시켜야 하고 이 과정을 수행하는 단계이다.
- 어셈블(assembling) 과정: 어셈블리어를 기계어로 변환하는 과정으로 목적 코드(object file)를 포함하는 목적 파일이 된다.
- 링킹(linking) 과정: 어셈블 과정에서 목적 파일이 생성되지만 목적 파일과 실행 파일은 다르다. 따라서 링킹 과정을 거친 이후에 실행 파일이 된다. 각각 다른 목적 코드를 하나로 묶어주는 과정을 말한다.

## CPU의 작동 원리
### CPU
CPU는 ALU, 제어 장치, 여러 개의 레지스터로 이루어져 있다. 그것들이 주고 받는 정보에 대해서 살펴보자.  

#### ALU

ALU는 레지스터로부터 **피연산자**, 제어 장치로부터 **제어 신호**를 받아 계산을 수행한다. ALU가 내보내는 값으로는 **결괏값**과 **플래그**가 있는데 결괏값은 레지스터에 저장한다. 메모리가 아닌 레지스터에 저장하는 이유는 위에서 살펴봤듯 레지스터에 저장하는 속도가 더 빠르기 때문이다. 플래그는 연산 결과에 대한 부가 정보(예: 양수? 음수?)를 담고 있다.

CPU마다 내보내는 플래그가 다르지만 공통적인 부분은 다음과 같다.
- 부호 플래그: 연산 결과의 부호를 나타낸다.
- 제로 플래그: 연산 결과가 0인지 여부를 나타낸다.
- 캐리 플래그: 연산 결과 올림수나 빌림수가 발생했는지 여부를 나타낸다.
- 오버플로우 플래그: 오버플로우 발생 여부를 나타낸다.
- 인터럽트 플래그: 인터럽트가 가능한지 나타낸다.
- 슈퍼바이저 플래그: 커널 모드로 실행 중인지, 사용자 모드로 실행 중인지 나타낸다.

#### 제어 장치
제어 장치가 받아들이는 정보로는 **클럭 신호**(clock sign), 플래그 레지스터가 보내는 **플래그**, 명령어 레지스터가 보내는 **해석할 명령어**, CPU를 제외한 다른 부품에서 보내는 **제어 신호**가 있다. 클럭 신호는 컴퓨터의 모든 부품을 일사불란하게 움직일 수 있게 하는 시간 단위이다.  
제어 장치가 내보내는 정보는 ALU나 레지스터 같이 **CPU 내부**로 전달하는 제어 신호가 있고 메모리나 입출력장치 같이 **CPU 외부**로 전달하는 제어 신호가 있다.

#### 레지스터
레지스터는 CPU 내부의 작은 임시저장장치로 볼 수 있다. CPU 내부에는 다양한 레지스터들이 있고, 각각 다른 역할을 한다. 그 중 대부분의 CPU가 갖고 있는 레지스터들은 아래와 같다.

1. 프로그램 카운터: 메모리에서 가져올 명령어의 주소를 저장한다.
2. 명령어 레지스터: 해석할 명령어를 저장한다.
3. 메모리 주소 레지스터: 메모리 주소를 저장한다.
4. 메모리 버퍼 레지스터: 메모리와 주고받을 값(데이터와 명령어)을 저장한다.
5. 플래그 레지스터: 연산 결과 또는 CPU 상태에 대한 부가적인 정보를 저장한다.
6. 범용 레지스터: 다양하고 일반적인 상황에서 자유롭게 사용할 수 있다.
7. 스택 포인터: 스택의 최상단을 가리키는 레지스터로 특별한 주소 지정에 사용한다.
8. 베이스 레지스터: 기준 주소를 저장하는 레지스터로 특별한 주소 지정에 사용한다.

> 여기서 말하는 특정 레지스터를 이용한 주소 지정 방식에는

- **스택 주소 지정 방식**: 스택과 스택 포인터를 이용한 방식이다.
- **변위 주소 지정 방식**: 오퍼랜드 필드의 값(변위)과 특정 레지스터의 값을 더하여 유효 주소를 얻는 방식이다. 이 특정 레지스터는 대부분 프로그램 카운터이거나 베이스 레지스터이다. 프로그램 카운터를 사용해 유효 주소를 얻어온다면 **상대 주소 지정 방식**이고, 베이스 레지스터를 사용한다면 **베이스 레지스터 주소 지정 방식**이라고 한다.

> 1-4번 레지스터 사용 예시를 보자  

메모리에 실행할 프로그램이 1000번지부터 1500번지까지 저장되어 있고, 각 명령어는 하나의 메모리 주소를 차지하고 있다고 가정해보자. 먼저, 프로그램 카운터에 1000번지 주소가 저장되고 이 주소는 메모리 주소 레지스터에 복사가 된다. 이후 주소 버스를 통한 주소와 제어 버스를 통한 메모리 읽기 신호가 메모리에 전송된다. 메모리는 1000번지에 저장되어 있는 데이터를 데이터 버스를 통해 메모리 버퍼 레지스터에 전송하고 이때 프로그램 카운터는 1이 증가해 1001이 된다. CPU는 메모리 버퍼 레지스터에 저장된 명령어를 해석하기 위해 명령어 레지스터에 복사를 한 뒤, 그 업무를 수행한다.

이런 순차적인 실행 흐름이 끊기는 경우가 있는데, 위에서 봤던 JUMP, CALL, RETURN 같은 특정 메모리 주소로 실행 흐름을 이동하는 명령어를 실행하거나 인터럽트가 발생하는 등이 이런 경우에 해당한다.

#### 명령어 사이클과 인터럽트

프로그램 속 명령어들은 일정한 주기가 반복되며 실행되는데 이걸 명령어 사이클이라고 한다. 가장 먼저 메모리에서 데이터, 명령어를 읽어오는 인출 사이클, 그걸 실행하는 실행 사이클이 메인으로 돌아간다. 여기서 메모리 접근이 더 필요한 경우 간접 사이클이 추가된다. 이런 정해진 흐름을 끊는게 인터럽트이고, 따라서 CPU가 꼭 주목해야할 상황에서 발생해야한다. 인터럽트의 종류는 아래와 같다.
1. **동기 인터럽트**(예외): CPU가 예기치 못한 상황을 접했을 때 발생한다.
    - 폴트
    - 트랩
    - 중단
    - 소프트웨어 인터럽트
2. **비동기 인터럽트**(하드웨어 인터럽트): 주로 입출력장치에 의해 발생한다. 문제의 발생보다는 알림과 같은 역할을 해서 CPU가 효율적으로 명령어를 처리할 수 있게 한다. 입출력장치는 CPU보다 느리기 때문에 인터럽트가 없다면 입출력장치가 자기의 업무를 하는 동안 CPU는 다른 일을 할 수가 없는데, 인터럽트가 있다면 CPU는 알림을 믿고 다른 작업을 처리할 수가 있다.
    - 막을 수 있는 인터럽트(maskable interrupt)
    - 막을 수 없는 인터럽트(non maskable interrupt)

> 하드웨어 인터럽트의 처리 순서는 보통 비슷한데
1. 입출력장치는 CPU에 인터럽트 요청 신호를 보낸다.
2. CPU는 실행 사이클이 끝나고 명령어를 인출하기 전 항상 인터럽트 여부를 확인한다.
3. CPU는 인터럽트 요청을 확인하고 인터럽트 플래그를 통해 현재 인터럽트를 받아들일 수 있는지 여부를 확인한다.
4. 인터럽트를 받아들일 수 있다면 CPU는 지금까지의 작업을 백업한다.
5. CPU는 인터럽트 벡터를 참조하여 인터럽트 서비스 루틴을 실행한다.
6. 인터럽트 서비스 루틴 실행이 끝나면 4에서 백업해 둔 작업을 복구하여 실행을 재개한다.

> 여기서 새로운 개념을 하나씩 알아보자
- **인터럽트 요청 신호**: 입출력장치가 CPU에게 "지금 끼어들어도 되나요?"라는 요청을 보내는 것이다.
- **인터럽트 플래그**: 플래그 레지스터 속 인터럽트 플래그를 확인해서 요청을 받아들일 수 있는지 확인한다. 이러한 플래그가 모든 인터럽트를 막을 수 있는건 아니다.
- **인터럽트 벡터**: 각각의 인터럽트를 구분하기 위한 정보이다.
- **인터럽트 서비스 루틴**: 인터럽트가 발생했을 때 해당 인터럽트를 어떻게 처리하면 되는지가 적혀있는 프로그램이다. 이 또한 프로그램이기에 메모리에 저장된다.

> 여기서 궁금한건 1500번지의 명령어를 수행하다가 인터럽트가 발생하면 10번지의 인터럽트 서비스 루틴을 수행하고 다시 1500번지로 돌아온다는 말인데, 기존에 프로그램 카운터에 저장된 1500번지 값을 10으로 덮어씌우면 될까?  

언제든 다시 원래의 실행 순서(여기선 1500번지)로 돌아와야하기 때문에 덮어씌우기 전에 스택에 프로그램 카운터, 메모리 주소 값, 메모리 버퍼 값 등을 저장해두고(**백업**), 복구하여 사용한다.