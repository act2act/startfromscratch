# 컴퓨터 구조

### 컴퓨터 구조를 왜 알아야하는가?
소프트웨어가 하드웨어와 어떻게 상호 작용하는지를 이해함으로써, 성능 최적화, 리소스 관리, 디버깅 과정에서 발생하는 문제를 더 잘 이해하고 해결할 수 있다.  

### 컴퓨터 구조는 크게 두 섹터로 볼 수 있다
1. 컴퓨터가 이해하는 정보
    - 데이터
    - 명령어
2. 컴퓨터의 핵심 부품
    - CPU
    - 메모리(주기억장치, 메인메모리)
    - 보조기억장치
    - 입출력장치

### 처음엔 간단한 정의 정도로 시작하자
1. 컴퓨터가 이해하는 정보
    - **데이터**: 컴퓨터는 `0, 1`만 이해할 수 있다. 이 0, 1을 가지고 숫자, 문자, 이미지, 동영상 같은 정적인 정보를 나타낸 것을 데이터라고 한다.  
    - **명령어**: 컴퓨터는 결국 명령어를 처리하는 기계이다.  

2. 컴퓨터의 핵심 부품
    - **CPU**; Central Processing Unit: 메모리에 저장된 명령어를 읽어 들이고, 해석하고, 실행하는 부품이다.
    - **메모리**: 현재 실행되는 프로그램의 데이터와 명령어를 저장하는 부품이다.
        - **RAM**; Random Access Memory: 휘발성 메모리로, 작업중인 파일을 한시적으로 저장한다.
        - **ROM**; Read Only Memory: 비휘발성 메모리로, 컴퓨터에 지시사항을 영구히 저장한다.
    - **보조기억장치**: USB, SD카드, SSD, 하드디스크 같이 대용량, 백업용으로 사용할 수 있는 장치이다.
    - **입출력장치**: 키보드, 모니터, 스피커 같이 컴퓨터 외부에서 컴퓨터 내부로 정보를 주고 받을 수 있는 장치이다.

### CPU를 조금 더 살펴보자
- CPU
    - **산술 논리 연산 장치**; Arithmetic & Logic Unit; ALU: 비교, 판단, 연산을 담당한다.
    - **제어 장치**; Control Unit; CU: 프로세서의 조작을 지시하는 역할을 담당한다.
    - **레지스터**: 컴퓨터의 프로세서 내에서 자료를 보관하는 아주 빠른 기억 장소이다.

### 핵심 부품이 서로 어떻게 작동하는지 알아보자
위의 네 가지 핵심 부품은 **메인보드**에서 결합된다. 메인보드에는 1. `주소 버스` 2. `데이터 버스` 3. `제어 버스` 라는 세 가지 시스템 버스(통로)가 있다. 이 시스템 버스를 통해서 각 부품들이 서로 정보를 주고 받을 수 있게 된다.  

#### Case 1. 메모리 값 읽어 들이기
1. 메모리 주소(1번지): 더하라, 3번지와 4번지를
2. 메모리 주소(2번지): 저장하라, 연산 결과를
3. 메모리 주소(3번지): 120
4. 메모리 주소(4번지): 100

*CPU는 메모리 주소 1번지에 저장된 명령어를 읽어 들이고 싶다!*   
메모리 읽기를 제어 버스를 통해, 1번지를 주소 버스를 통해 보낸다. 메모리는 그 신호를 받고 해당 정보를 데이터 버스를 통해 다시 CPU로 보낸다. CPU는 받은 정보를 레지스터에 저장해놓고 순서대로 처리한다.

#### Case 2. 메모리 값 쓰기
*CPU는 값을 쓰고 싶다!*  
레지스터에 저장된 값(220)을 데이터 버스에 통해, 5번지를 주소 버스에 통해, 메모리 쓰기를 제어 버스에 통해 보낸다. 메모리는 그 신호를 받고 5번지에 해당 값을 저장해놓는다.

## 데이터로 돌아가서
> 컴퓨터는 오직 0, 1만 이해하는데 1보다 큰 수를 어떻게 알 수 있을까?

### 0과 1로 숫자를 표현하는 방법

#### 정보 단위
0, 1을 표현하는 가장 작은 정보 단위를 `비트`라고 한다. 비트를 전구라고 본다면 전구가 꺼진 상태를 0, 전구가 켜진 상태를 1이고, 1 비트는 두 가지 정보를 담고 있다는걸 알 수 있다. n비트의 정보 단위의 수 = 2^n으로 표현할 수 있다. 프로그램은 수많은 비트로 이루어져 있지만 일반적으로 바이트, 킬로바이트, 메가바이트, 기가바이트, 테라바이트 등 더 큰 단위로 표현한다.
- 1 바이트(byte): 8 비트(bit)
- 1 킬로바이트(kB): 1000 byte
- 1 메가바이트(MB): 1000 kB
- 1 기가바이트(GB): 1000 MB
- 1 테라바이트(TB): 1000 GB  

CPU가 한번에 처리할 수 있는 정보의 크기 단위를 `워드`라고 한다.  

#### 이진법(binary)
0과 1로 숫자를 표현하는 방법이다. 숫자가 1을 넘어가는 시점에 자리올림을 하여 사용한다.
- 십진수 : 이진수
- 1 : 1
- 2 : 1 0
- 3 : 1 1
- 4 : 1 0 0
- 5 : 1 0 1
- 6 : 1 1 0
- 7 : 1 1 1
- 8 : 1 0 0 0

> 그럼 음수는 어떻게 표현할까?

어떤 수를 그보다 큰 2^n에서 뺀 값을 음수로 사용하는 `2의 보수법`을 사용한다. 쉽게 구하는 방법은 모든 0과 1을 뒤집고 1을 더하면 된다. 예를 들어, 1 1의 음수를 구한다고 할 때 0 0으로 뒤집고 1을 더해주어 0 1을 만들면 된다.  

> -1011을 표현한 0101과 십진수 5를 표현한 0101은 어떻게 구분할까?

CPU 내부엔 양수와 음수를 구분하는 플래그 레지스터가 존재한다.

> 이진법으로 표현하면 숫자가 너무 길어질 것 같은데..?

때문에 데이터를 표현할 때 십육진법도 많이 사용한다. 십육진법은 수가 15를 넘어가는 시점에 자리올림을 해서 표현한다.
- 십진수 : 십육진수
- 0 : 0
- 1 : 1
- 2 : 2
- 3 : 3
- 4 : 4
- 5 : 5
- 6 : 6
- 7 : 7
- 8 : 8
- 9 : 9
- 1 0 : A
- 1 1 : B
- 1 2 : C
- 1 3 : D
- 1 4 : E
- 1 5 : F
- 1 6 : 1 0
- 1 7 : 1 1
- ... : ...

***십진수의 1 0과 십육진수의 1 0을 어떻게 구분하지?***

1. 10(16) : 수학적 표기 방식
2. 0x10 : 코드상 표기 방식

### 0과 1로 문자를 표현하는 방법

#### 먼저 용어를 살펴보자
- 문자 집합: 컴퓨터가 이해할 수 있는 문자 모음
- 인코딩(encoding): 문자를 0과 1로 이루어진 문자 코드로 변환하는 과정
- 디코딩(decoding): 0과 1로 표현된 문자 코드를 문자로 변환하는 과정

#### 대표적인 문자 집합
ASCII 코드는 초창기 문자 집합 중 하나이다. 하나의 문자를 표현하기 위해서 8 비트가 사용되고 그 중 1 비트는 오류 검출을 위해 사용되는 parity bit이므로 실제 문자 표현에 7 비트가 사용된다. 한글을 포함한 다른 언어를 표현할 수 없다는 한계가 있다.  

> 모든 언어, 특수문자까지 통일된 문자 집합, 그리고 인코딩 방식을 사용하면 어떨까?

그렇게 생겨난게 `유니코드 문자 집합`과 `utf-8` 인코딩 방식이다. 이 유니코드는 한글, 영어, 특수 문자, 이모티콘까지 사용할 수 있어 현대 문자 표현에 중요한 위치에 있다. utf-8 인코딩은 1 byte~4 byte까지 될 수 있는 가변 길이를 갖고 있다. 이 인코딩 결과가 몇 byte가 될지는 유니코드에 부여된 값에 따라 다르다.

### 이제 소스 코드와 명령어를 보자
C++로 작성된 소스 코드를 컴퓨터는 바로 알아들을 수 없다. C++, java, python 같은 언어는 인간이 이해하기 위한 `고급 언어`에 속한다. 컴퓨터는 이 고급 언어를 알아듣기 위해 `저급 언어`로 변환시킨다. 이 저급 언어는 명렁어들로 이루어져 있고 위에서 본 이진법이나 십육진법을 사용하는 `기계어`와 그걸 인간의 이해를 위해 변환시킨 `어셈블리어`로 나뉜다.  

고급 언어를 저급 언어로 변환하는 과정은 크게 두 가지로 `컴파일`과 `인터프리트` 과정이 있다.  하나씩 살펴보자.

- 컴파일 언어: 고급 언어로 작성된 소스 코드는 컴파일러를 통해 목적 코드로 변환된다.
- 인터프리트 언어: 컴파일 언어는 소스 코드 전체를 컴파일하지만 인터프리트 언어는 인터프리터에 의해 소스 코드 한 줄씩 실행이 되기 때문에 소스 코드 전체가 저급 언어로 변환되기까지 기다릴 필요가 없다.  

이 두 언어가 흑과 백처럼 칼로 자르듯 양분되는 개념은 아니다.

> 명령어 하나하나는 어떻게 생겼을까?  

"무엇을 대상으로, 무엇을 수행하라" 구조로 일상에서 명령을 내리는 것과 크게 다르지 않다. 예를 들면, "더하라, 100과 120을" 같이 "수행할 연산, 연산에 사용될 데이터 혹은 위치" 형태를 띄고 있다. 이를 정확하게는 `"연산 코드, 오퍼랜드"` 구조라고 한다.  

#### Operand
연산에 사용될 데이터 혹은 저장된 위치라고 했지만 실제로 연산에 사용될 데이터의 저장된 위치가 더 많이 사용되어 이를 **주소 필드**라고 부르기도 한다. 연산에 사용될 데이터의 저장된 위치만을 부를 땐 **유효 주소**(effective address)라고 한다. 이 유효 주소를 찾는 방식이 여러 개가 있는데 그걸 **명령어 주소 지정 방식**(addressing modes)라고 한다.  

##### 명령어 주소 지정 방식
- 즉시 주소 지정 방식
    - 가장 간단한 형태의 주소 지정 방식으로 연산에 사용할 데이터를 오퍼랜드 필드에 직접 명시한다. 연산에 사용할 데이터의 크기가 작아질 순 있지만 빠르다는 특징을 갖고 있다.
- 직접 주소 지정 방식
    - 오퍼랜드 필드에 유효 주소를 직접적으로 명시하는 방법이다. 유효 주소를 표현할 수 있는 크기가 연산 코드만큼 줄어드는 점이 있다.
- 간접 주소 지정 방식
    - 오퍼랜드 필드에 유효 주소의 주소를 명시하는 방법이다. 앞선 방식들에 비해 속도가 느린 특징이 있다.
- 레지스터 주소 지정 방식
    - 연산에 사용할 데이터가 저장된 레지스터를 명시하는 방법이다. *메모리에 접근하는 속도보다 레지스터에 접근하는 것이 빠르다.*
- 레지스터 간접 주소 지정 방식
    - 연산에 사용할 데이터를 메모리에 저장하고 그 주소를 저장한 레지스터를 오퍼랜드 필드에 명시하는 방식이다.

> 근데 왜 데이터가 아닌 주소를 저장하는거지?

주소 명령어에서 표현할 수 있는 데이터 크기가 제한되기 때문이다.

#### 연산 코드
연산 코드의 종류와 생김새는 CPU마다 다양하다. 일반적인 기능은 아래와 같다.
1. 데이터 전송
    - MOVE: 데이터를 옮겨라
    - STORE: 메모리에 저장하라
    - LOAD(FETCH): 메모리에서 CPU로 데이터를 가져와라
    - PUSH: 스택에 데이터를 저장하라
    - POP: 스택의 최상단 데이터를 가져와라
2. 산술/논리 연산
    - ADD/SUBTRACT/MULTIPLY/DIVIDE: 사칙연산을 수행하라
    - INCREMENT/DECREMENT: 오퍼랜드에 1을 더하라/빼라
    - AND/OR/NOT
    - COMPARE: 두 개의 숫자 또는 True/False 값을 비교하라
3. 제어 흐름 변경
    - JUMP: 특정 주소로 실행 순서를 옮겨라
    - CONDITIONAL JUMP: 조건에 부합할 때 JUMP 연산을 수행하라
    - HALT: 프로그램의 실행을 멈춰라
    - CALL: 되돌아올 주소를 저장한 채 특정 주소로 실행 순서를 옮겨라
    - RETURN: CALL을 호출할 때 저장했던 주소로 돌아가라
4. 입출력 제어
    - READ(INPUT): 특정 입출력 장치로부터 데이터를 읽어라
    - WRITE(OUTPUT): 특정 입출력 장치로 데이터를 써라
    - START IO: 입출력 장치를 시작하라
    - TEST IO: 입출력 장치의 상태를 확인하라

### C언어 컴파일 과정을 살펴보자
**test.c > 전처리기 > test.i > 컴파일러 > test.s > 어셈블러 > test.o > 링커 > test.exe**

- 전처리(preprocessing) 과정: 본격적으로 컴파일하기 전에 준비 작업을 하는 것으로 외부의 라이브러리를 포함시키거나 프로그래밍의 편의를 위해 작성된 매크로를 변환하거나 컴파일할 영역을 명시하는 등의 작업을 말한다.
- 컴파일(compile) 과정: 전처리가 완료 되어도 여전히 소스 코드이기 때문에 저급 언어로 변환시켜야 하고 이 과정을 수행하는 단계이다.
- 어셈블(assembling) 과정: 어셈블리어를 기계어로 변환하는 과정으로 목적 코드(object file)를 포함하는 목적 파일이 된다.
- 링킹(linking) 과정: 어셈블 과정에서 목적 파일이 생성되지만 목적 파일과 실행 파일은 다르다. 따라서 링킹 과정을 거친 이후에 실행 파일이 된다. 각각 다른 목적 코드를 하나로 묶어주는 과정을 말한다.

## CPU의 작동 원리
### CPU
CPU는 ALU, 제어 장치, 여러 개의 레지스터로 이루어져 있다. 그것들이 주고 받는 정보에 대해서 살펴보자.  

#### ALU

ALU는 레지스터로부터 **피연산자**, 제어 장치로부터 **제어 신호**를 받아 계산을 수행한다. ALU가 내보내는 값으로는 **결괏값**과 **플래그**가 있는데 결괏값은 레지스터에 저장한다. 메모리가 아닌 레지스터에 저장하는 이유는 위에서 살펴봤듯 레지스터에 저장하는 속도가 더 빠르기 때문이다. 플래그는 연산 결과에 대한 부가 정보(예: 양수? 음수?)를 담고 있다.

CPU마다 내보내는 플래그가 다르지만 공통적인 부분은 다음과 같다.
- 부호 플래그: 연산 결과의 부호를 나타낸다.
- 제로 플래그: 연산 결과가 0인지 여부를 나타낸다.
- 캐리 플래그: 연산 결과 올림수나 빌림수가 발생했는지 여부를 나타낸다.
- 오버플로우 플래그: 오버플로우 발생 여부를 나타낸다.
- 인터럽트 플래그: 인터럽트가 가능한지 나타낸다.
- 슈퍼바이저 플래그: 커널 모드로 실행 중인지, 사용자 모드로 실행 중인지 나타낸다.

#### 제어 장치
제어 장치가 받아들이는 정보로는 **클럭 신호**(clock sign), 플래그 레지스터가 보내는 **플래그**, 명령어 레지스터가 보내는 **해석할 명령어**, CPU를 제외한 다른 부품에서 보내는 **제어 신호**가 있다. 클럭 신호는 컴퓨터의 모든 부품을 일사불란하게 움직일 수 있게 하는 시간 단위이다.  
제어 장치가 내보내는 정보는 ALU나 레지스터 같이 **CPU 내부**로 전달하는 제어 신호가 있고 메모리나 입출력장치 같이 **CPU 외부**로 전달하는 제어 신호가 있다.

#### 레지스터
레지스터는 CPU 내부의 작은 임시저장장치로 볼 수 있다. CPU 내부에는 다양한 레지스터들이 있고, 각각 다른 역할을 한다. 그 중 대부분의 CPU가 갖고 있는 레지스터들은 아래와 같다.

1. 프로그램 카운터: 메모리에서 가져올 명령어의 주소를 저장한다.
2. 명령어 레지스터: 해석할 명령어를 저장한다.
3. 메모리 주소 레지스터: 메모리 주소를 저장한다.
4. 메모리 버퍼 레지스터: 메모리와 주고받을 값(데이터와 명령어)을 저장한다.
5. 플래그 레지스터: 연산 결과 또는 CPU 상태에 대한 부가적인 정보를 저장한다.
6. 범용 레지스터: 다양하고 일반적인 상황에서 자유롭게 사용할 수 있다.
7. 스택 포인터: 스택의 최상단을 가리키는 레지스터로 특별한 주소 지정에 사용한다.
8. 베이스 레지스터: 기준 주소를 저장하는 레지스터로 특별한 주소 지정에 사용한다.

> 여기서 말하는 특정 레지스터를 이용한 주소 지정 방식에는

- **스택 주소 지정 방식**: 스택과 스택 포인터를 이용한 방식이다.
- **변위 주소 지정 방식**: 오퍼랜드 필드의 값(변위)과 특정 레지스터의 값을 더하여 유효 주소를 얻는 방식이다. 이 특정 레지스터는 대부분 프로그램 카운터이거나 베이스 레지스터이다. 프로그램 카운터를 사용해 유효 주소를 얻어온다면 **상대 주소 지정 방식**이고, 베이스 레지스터를 사용한다면 **베이스 레지스터 주소 지정 방식**이라고 한다.

> 1-4번 레지스터 사용 예시를 보자  

메모리에 실행할 프로그램이 1000번지부터 1500번지까지 저장되어 있고, 각 명령어는 하나의 메모리 주소를 차지하고 있다고 가정해보자. 먼저, 프로그램 카운터에 1000번지 주소가 저장되고 이 주소는 메모리 주소 레지스터에 복사가 된다. 이후 주소 버스를 통한 주소와 제어 버스를 통한 메모리 읽기 신호가 메모리에 전송된다. 메모리는 1000번지에 저장되어 있는 데이터를 데이터 버스를 통해 메모리 버퍼 레지스터에 전송하고 이때 프로그램 카운터는 1이 증가해 1001이 된다. CPU는 메모리 버퍼 레지스터에 저장된 명령어를 해석하기 위해 명령어 레지스터에 복사를 한 뒤, 그 업무를 수행한다.

이런 순차적인 실행 흐름이 끊기는 경우가 있는데, 위에서 봤던 JUMP, CALL, RETURN 같은 특정 메모리 주소로 실행 흐름을 이동하는 명령어를 실행하거나 인터럽트가 발생하는 등이 이런 경우에 해당한다.

#### 명령어 사이클과 인터럽트

프로그램 속 명령어들은 일정한 주기가 반복되며 실행되는데 이걸 명령어 사이클이라고 한다. 가장 먼저 메모리에서 데이터, 명령어를 읽어오는 인출 사이클, 그걸 실행하는 실행 사이클이 메인으로 돌아간다. 여기서 메모리 접근이 더 필요한 경우 인출 사이클에서 간접 사이클이 추가되고 인터럽트가 발생하면 실행 사이클에서 인터럽트 사이클이 추가된다. 이런 정해진 흐름을 끊는게 인터럽트이고, 따라서 CPU가 꼭 주목해야할 상황에서 발생해야한다. 인터럽트의 종류는 아래와 같다.
1. **동기 인터럽트**(예외): CPU가 예기치 못한 상황을 접했을 때 발생한다.
    - 폴트
    - 트랩
    - 중단
    - 소프트웨어 인터럽트
2. **비동기 인터럽트**(하드웨어 인터럽트): 주로 입출력장치에 의해 발생한다. 문제의 발생보다는 알림과 같은 역할을 해서 CPU가 효율적으로 명령어를 처리할 수 있게 한다. 입출력장치는 CPU보다 느리기 때문에 인터럽트가 없다면 입출력장치가 자기의 업무를 하는 동안 CPU는 다른 일을 할 수가 없는데, 인터럽트가 있다면 CPU는 알림을 믿고 다른 작업을 처리할 수가 있다.
    - 막을 수 있는 인터럽트(maskable interrupt)
    - 막을 수 없는 인터럽트(non maskable interrupt)

> 하드웨어 인터럽트의 처리 순서는 보통 비슷한데
1. 입출력장치는 CPU에 **인터럽트 요청 신호**를 보낸다.
2. CPU는 실행 사이클이 끝나고 명령어를 인출하기 전 항상 인터럽트 여부를 확인한다.
3. CPU는 **인터럽트 요청**을 확인하고 **인터럽트 플래그**를 통해 현재 인터럽트를 받아들일 수 있는지 여부를 확인한다.
4. 인터럽트를 받아들일 수 있다면 CPU는 지금까지의 작업을 백업한다.
5. CPU는 **인터럽트 벡터**를 참조하여 **인터럽트 서비스 루틴**을 실행한다.
6. 인터럽트 서비스 루틴 실행이 끝나면 4에서 백업해 둔 작업을 복구하여 실행을 재개한다.

> 여기서 새로운 개념을 하나씩 알아보자
- **인터럽트 요청 신호**: 입출력장치가 CPU에게 "지금 끼어들어도 되나요?"라는 요청을 보내는 것이다.
- **인터럽트 플래그**: 플래그 레지스터 속 인터럽트 플래그를 확인해서 요청을 받아들일 수 있는지 확인한다. 이러한 플래그가 모든 인터럽트를 막을 수 있는건 아니다.
- **인터럽트 벡터**: 각각의 인터럽트를 구분하기 위한 정보이다.
- **인터럽트 서비스 루틴**: 인터럽트가 발생했을 때 해당 인터럽트를 어떻게 처리하면 되는지가 적혀있는 프로그램이다. 이 또한 프로그램이기에 메모리에 저장된다.

> 여기서 궁금한건 1500번지의 명령어를 수행하다가 인터럽트가 발생하면 10번지의 인터럽트 서비스 루틴을 수행하고 다시 1500번지로 돌아온다는 말인데, 기존에 프로그램 카운터에 저장된 1500번지 값을 10으로 덮어씌우면 될까?  

언제든 다시 원래의 실행 순서(여기선 1500번지)로 돌아와야하기 때문에 덮어씌우기 전에 스택에 프로그램 카운터, 메모리 주소 값, 메모리 버퍼 값 등을 저장해두고(**백업**), 복구하여 사용한다.

## 빠른 CPU를 위한 설계 기법
이 장에선 클럭, 코어/멀티코어, 스레드/멀티 스레드의 개념을 다룬다. 위에서 봤듯이 모든 부품은 클럭 신호에 맞춰 일사불란하게 움직인다.
> 그럼 클럭 신호 주기를 짧게 만들면 CPU가 빨라지겠네?  

일반적으로 그 답은 Yes이다. **클럭** 속도는 헤르츠(Hz)단위로 측정되고 이는 1초에 클럭이 반복되는 횟수를 보여준다. 100 Hz라면 클럭이 1초에 100번 반복되는 것이다. 하지만, 필요 이상으로 클럭을 높이면 발열이 심해진다.  

빠른 CPU를 위해 클럭 속도 이외에 할 수 있는 것이 코어 수를 늘리는 방법과 스레드 수를 늘리는 방법이다. **코어**는 전통적인 CPU를 현대적인 관점에서 재해석이 필요하다. 위에서 본 ALU, 제어장치, 레지스터로 이루어진 CPU 하나만 가진게 전통 CPU였다면 현대의 CPU는 이런 하나의 CPU, 즉 코어를 여러 개 가질 수 있다.
> 그럼 코어 수에 따라 비례해서 빨라지겠네?

꼭 그렇지는 않다. 소프트 리밋, 하드 리밋 개념처럼 일정량 이상의 성능은 그 효용이 꼭 선형, 지수적으로 증가하지는 않는다.  

**스레드**란 실행 흐름의 단위를 말한다. 크게는 아래와 같이 볼 수 있다.
- **하드웨어적 스레드**: 하나의 코어가 동시에 처리하는 명령어 단위를 말한다. 예를 들어, 1개의 코어가 동시에 하나의 명령어만 처리한다면 그건 1코어 1스레드 CPU로 볼 수 있다.
- **소프트웨어적 스레드**: 하나의 프로그램에서 독립적으로 실행되는 단위를 말한다. 이런 단위를 여러개 만들면 하나의 프로그램에서 동시에 여러 기능을 실행하게 만들 수 있다.


*"1코어 1스레드 CPU도 여러 소프트웨어적 스레드를 가질 수 있다."*

하드웨어적 스레드에서 코어 수나 스레드 수를 메모리 입장에서 정확하게 알지 못한다. 메모리 입장에서 동시에 4개의 업무가 주어지면 그냥 4코어인가..? 라고 추측할 뿐이다. 이런 관점에서 **논리 프로세서**라고 부르기도 한다.

### 명령어 병렬 처리 기법
CPU를 빠르게 만들 수 있도록 설계하는 것도 중요하지만 효율적으로 시간을 관리하며 명령어를 처리하는 것도 중요하다.

#### 명령어 파이프라이닝
하나의 명령어가 처리되는 과정을 비슷한 시간 간격으로 나누면 아래와 같다.  

1. 명령어 인출
2. 명령어 해석
3. 명령어 실행
4. 결과 저장

CPU는 각 단계가 겹치지 않는다면 동시에 실행시킬 수 있다. 명령어 파이프라인을 사용하지 않는다면 실행에 걸리는 시간이 길어진다. 하지만, 매번 성능 향상을 가져오는 건 아닌데 그런 **파이프라인 위험**에 대해서 살펴보자.

- **파이프라인 위험**(Hazard)
    - **데이터 위험**: 명령어 간의 의존성에 의해 발생한다. 하나의 명령어가 실행되기 위해서 다른 명령어의 결괏값이 필요한 경우가 있을 수 있다.
    - **제어 위험**: 프로그램 카운터의 갑작스러운 변화에 의해 발생한다.
    - **구조적 위험**: 서로 다른 명령어가 같은 CPU 부품을 쓰려고 할 때 발생한다.

CPU 내부에 여러 개의 명령어 파이프라인을 두는 구조를 **슈퍼스칼라**라고 한다. 이론적으로는 파이프라인 수의 비례해서 처리 속도가 증가하지만, 현실에선 파이프라인 위험도 증가하기 때문에 비례해서 증가하지 않는다.

#### 비순차적 명령어 처리(Out of Order Execution; OOOE)
위에서 본건 순차적 명령어 처리 방법인 반면, 비순차적 명령어 처리 방법은 명령어 간 합법적인 새치기로 볼 수 있다. 하지만, 아무 명령어나 순서를 바꿀 수 있는건 아니다. 명령어 간 의존성이 없어서 전체 프로그램의 실행에 영향을 끼치지 않는 경우에만 변경이 가능하다.

### 명령어 집합 구조와 CISC & RISC
> 명령어가 어떻게 생겨야 명령어 파이프라이닝에 유리할까?

이 질문에 대한 대답을 해보자. 먼저, 질문에서 유추할 수 있듯이 CPU마다 명령어의 구조, 연산, 주소 지정 방식이 다르다. **명령어 집합**(구조)란 CPU가 이해할 수 있는 명령어들의 모음을 말한다. 즉, 제조사 저마다의 명령어 집합 구조를 사용한다.

이런 명령어 집합의 대표적인 두 종류는 아래와 같다.
1. **CISC**(Complex Instruction Set Computer): 복잡하고 형태와 크기가 다양한 가변 길이 명령어를 사용한다. 명령어 하나하나가 강력한 기능을 제공해 상대적으로 적은 수의 명령어로도 프로그램 실행이 가능하다. 하지만, 명령어 하나가 워낙 복잡하고 다양한 기능을 제공해서 실행 시간이 일정하지 않고 여러 클럭 주기가 필요하여 명령어 파이프라이닝에 불리하다는 단점을 갖고 있다.
2. **RISC**(Reduced Instruction Set Computer): 명령어의 종류가 적고, 짧고 규격화된 명령어를 사용한다. 메모리 접근을 최소화하고 레지스터 활용을 높이는 방식을 갖는다. 하지만, 더 적은 명령어 수를 갖고 있어 프로그램 실행 시 더 많은 명령어를 사용해야한다는 점이 있다.

## RAM
기억을 되짚어보면, 컴퓨터의 핵심 부품에는 CPU, 메모리, 보조기억장치, 입출력장치 이렇게 4가지가 있었다. 메모리(주기억장치)의 종류에는 크게 RAM과 ROM이 있고 보통 메모리라고 언급할 땐 이 RAM을 지칭하는 경우가 많다.  

RAM은 실행할 프로그램을 일시적으로 진열해놓는 휘발성 메모리이고, 보조기억장치는 영구적인 저장의 역할을 하는 비휘발성 메모리이다.  

> RAM이 크면 뭐가 좋을까?

책(프로그램)과 책상(RAM)과 책장(보조기억장치)을 떠올려보자. 책상이 작으면 한번에 많은 책을 올려둘 수 없고 매번 다른 책을 가져와야하는 번거로움이 생긴다. 반면, 책상이 크면 여러 책을 올려둘 수 있어 동시에 여러 책을 읽을 수 있게 된다.  

이런 RAM의 종류는 다음과 같다.
1. **DRAM**(Dynamic RAM): 저장된 데이터가 동적으로 사라지는 RAM을 말한다. 데이터의 소멸을 막으려면 주기적으로 재활성화 해주어야한다. 상대적으로 저렴하고 소비전력이 낮고 집적도가 높아 대용량 설계에 용이해서 대부분의 메모리에 사용된다.
2. **SRAM**(Static RAM): 저장된 데이터가 사라지지 않는 RAM을 말한다. 일반적으로 DRAM보다 입출력 속도가 빠르지만, 소비전력이 높고 집적도가 낮아 대용량 설계에 불리하다. 따라서, 대용량 설계가 필요 없고 속도가 빠른 RAM이 필요한 캐시 메모리에 사용된다.
3. **SDRAM**(Synchronous DRAM): 클럭 신호와 동기화된 DRAM을 말한다.
4. **DDR SDRAM**(Double Data Rate SDRAM): 대역폭을 넓혀 속도를 빠르게 만든 SDRAM을 말한다. 최근 가장 대중적인 RAM으로 볼 수 있다. 대역폭은 데이터를 주고 받을 수 있는 도로를 말한다. SDR SDRAM이면 1차선 도로와 같고 DDR SDRAM이면 2차선 도로와 같다. 추가로 DDR2 SDRAM은 4차선 도로로 볼 수 있고 DDR3, DDR4도 있다.  

### 메모리의 주소 공간
메모리의 주소 공간은 크게 두 가지로 볼 수 있다.
1. **논리 주소**: CPU와 실행 중인 프로그램 관점에서 바라본 주소를 말한다. 논리 주소는 프로그램 A는 0번지에서 A번지까지, 프로그램 B는 0번지에서 B번지까지처럼 같은 주소가 반복될 수 있다.
2. **물리 주소**: 메모리 관점에서 바라본 실제 하드웨어 상의 주소를 말한다. 0번지는 하나뿐이고 각 프로그램에 할당된 고유한 주소를 갖는다.

> 왜 주소 공간을 나눴을까?

CPU와 실행중인 프로그램은 메모리 몇번지에 어떤 데이터가 저장되어 있는지 전부 다 알지 못한다. 그 값이 시시때때로 변하기 때문이다.

> 물리 주소와 논리 주소 간의 변환은 어떻게 이루어질까?

**Memory Management Unit**; MMU(메모리 관리 장치)라는 하드웨어에 의해 변환된다. MMU는 논리 주소와 베이스 레지스터 값을 더해 변환시킨다.

> 다른 프로그램의 주소를 침범하는 명령어를 실행시켜도 안전할까?

애꿎은 다른 프로그램의 메모리를 삭제하는 것이기 때문에 당연히 안된다. 따라서, **메모리 보호**라는 방법을 고안한다. 이는 **한계 레지스터**를 통해 달성할 수 있다. 한계 레지스터는 프로그램의 영역을 침범할 수 있는 명령어의 실행을 막는다. 프로그램 주소의 시작점인 베이스 레지스터와 끝지점인 한계 레지스터 값을 이용해 물리 주소의 범위를 지정한다.  

이렇게 CPU에서 메모리에 접근할 때마다 논리 주소 값이 한계 레지스터 값보다 작은지 확인한다.  

### 캐시 메모리
먼저, CPU가 메모리에 접근하는 시간은 CPU 연산 속도에 비해 느리다는 점을 상기시켜놓자.

#### 저장 장치 계층 구조(memory hierarchy)
1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
2. 속도가 빠른 저장 장치는 저장 용량이 작고 비싸다.

`보조기억장치 < 메모리 < 레지스터` 순으로 볼 수 있다.

> 그래서 캐시 메모리가 뭔데?

CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치이다. CPU의 연산 속도와 메모리 접근 속도 사이에 차이를 조금이라도 줄이고자 탄생했다.  

편의점과 마트 비유

캐시 메모리를 반영한 저장 장치 계층 구조는 아래와 같다.  

`보조기억장치 < 메모리 < 캐시 메모리 < 레지스터`

#### 계층적 캐시 메모리
L1-L2-L3 캐시로 분리하며, 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치해 있다. 계층적 캐시 메모리까지 반영한 저장 장치 계층 구조는 아래와 같다.

`보조기억장치 < 메모리 < L3 < L2 < L1 < 레지스터`

#### 참조 지역성의 원리(Locality of Reference)
캐시 메모리는 메모리보다 용량이 작으므로 모든 내용을 다 저장할 수 없을거다. 따라서, CPU가 자주 사용할법한 데이터/명령어를 예측하는 게 필요하다. 예측이 들어맞는 경우를 **캐시 히트**라고 하고, 벗어나는 경우를 **캐시 미스**라고 한다. 캐시 히트 / (캐시 히트 + 캐시 미스) 식을 통해  **캐시 적중률**을 구할 수 있다.  

이렇게 CPU가 메모리에 접근할 때의 경향을 참조하여 예측하는 방법을 **참조 지역성의 원리**라고 한다.  
1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
2. CPU는 접근한 메모리 공간 근처를 접근하는 경향이 있다.

## 보조기억장치
대표적인 보조기억장치인 하드 디스크와 플래시 메모리에 대해서 알아보자.

- **하드 디스크**: 자기적인 방식으로 데이터를 저장한다.
    - 구성: 수많은 N극과 S극으로 이루어진 여러 겹의 **플래터**와 그걸 회전시키는 **스핀들**, 그 플래터를 읽어들이는 **디스크 암**과 **헤드**로 이루어져 있다. 생김새와 사용 방법이 LP판과 유사하다.
    - 저장 단위: 기본적으로 **트랙**과 **섹터** 단위로 데이터를 저장한다. 하나 이상의 섹터를 묶어 **블록**이라고 말하기도 한다. 같은 트랙을 모아 **실린더**라고 한다.
    - 데이터 접근 과정: 하드 디스크가 저장된 데이터에 접근하는 시간을 크게 세 가지로 나눈다.
        1. **탐색 시간**: 접근하려는 데이터가 저장된 트랙까지 헤드를 이동시키는 시간을 말한다.
        2. **회전 지연**: 헤드가 있는 곳으로 플래터를 회전시키는 시간을 말한다.
        3. **전송 시간**: 하드 디스크와 컴퓨터 간 데이터를 전송하는 시간을 말한다.
- **플래시 메모리**: 전기적으로 데이터를 읽고 쓰는 반도체 기반 저장 장치이다.
    - 종류
        - NAND 플래시 메모리
        - NOR 플래시 메모리
    - 저장 단위: 데이터를 저장하는 가장 작은 단위를 **셀**이라고 한다. 이 cell이 모여 page, page가 모여 block, block이 모여 plane, plane이 모여 die가 된다. 그리고 읽기/쓰기와 삭제의 단위가 다르다. 읽기/쓰기는 page 단위로 이루어지지만, 삭제는 block 단위가 사용된다.
        - 한 셀에 1비트 저장: SLC type
        - 한 셀에 2비트 저장: MLC type
        - 한 셀에 3비트 저장: TLC type
        - 한 셀에 4비트 저장: QLC type
> 위 셀을 집으로, 비트를 사람으로 빗대어 이해할 수 있다.

SLC 타입은 한 집에 한 명이 살고 있는 상태로 볼 수 있다. 혼자 지내기 때문에 외출과 귀가(입출력)가 자유롭고 빠를거다. 또, 집 사용이 적기 때문에 수명이 길다. 하지만 혼자 월세를 다 내기 때문에 비용이 많이 든다(용량 대비 가격이 비싸다). 반면 MLC 타입은 한 집에 두 명이 같이 사는 상태로 볼 수 있고, 외출/귀가는 상대적으로 느릴지라도 비용이 절감된다. 두 명이 사용하니 수명은 상대적으로 짧아진다.

> 위 페이지 단위는 상태를 가질 수 있다.

- Free: 어떠한 데이터도 저장하고 있지 않아 새로운 데이터를 저장할 수 있는 상태를 말한다.
- Valid: 이미 유효한 데이터를 저장하고 있는 상태를 말한다.
- Invalid: 유효하지 않은 데이터를 저장하고 있는 상태를 말한다.  

> 플래시 메모리의 동작 예시를 보면,

한 블록(4 페이지) 안에 A, B, C 데이터가 저장되어 있다. 여기서 A를 A'로 수정하고 싶다면 A만 따로 바꿀 수가 있을까? 없다. 삭제는 블록 단위로 이뤄져야하기 때문이다. 따라서, A 페이지를 Invalid 상태로 변경 이후 남은 페이지에 A'를 써넣는다. 하지만, 이렇게 되면 쓰레기 값이 계속 남아있어 용량을 차지하게 된다. 여기서 **가비지 컬렉션**이 나온다. 가비지 컬렉션은 유효한 페이지들만 새 블록으로 복사하고 기존의 블록을 삭제시켜 공간을 정리한다.

### RAID(Redundant Array of Independent Disks)
하드 디스크나 SSD로 사용하는 기술로, 데이터의 안전성과 높은 성능을 위해 여러 물리적 보조기억장치를 마치 하나의 논리적 보조기억장치처럼 사용하는 기술이다.  

RAID를 구성하는 기술로 RAID 0, RAID 1, ..., RAID 4, RAID 5, RAID 6, 여기서 파생된 RAID 10, RAID 50 등과 같은 RAID 레벨이 있다.
- **RAID 0**: 데이터를 단순히 나누어 저장하는 구성 방식이고, 이걸 stripe(줄무늬처럼 분산되어 저장된 데이터), striping 한다고 말한다. 이런 방식은 입출력 속도가 향상될 수 있지만, 저장된 정보가 안전하지 않다는 단점이 존재한다.
- **RAID 1**: 복사본을 만드는 mirroring 방식을 택한다. 그만큼 쓰는 속도가 느릴 수 있다.
- **RAID 4**: RAID 1처럼 완전한 복사본을 만드는 대신 오류를 검출하고 복구할 수 있는 parity bit를 저장하는 방식이다. parity disk에서 병목 현상이 발생할 수 있다.
- **RAID 5**: RIAD 4의 병목 현상을 해결하기 위해 parity bit를 분산하여 저장하는 방식이다.
- **RAID 6**: 두 종류의 parity bit를 사용하는 방식이다. 쓰는 속도가 느리다는 점이 있다.

## 입출력장치
입출력장치는 CPU, 메모리보다 다루기가 더 까다롭다. 그 이유로는 입출력장치의 종류가 너무 많아서 정보를 주고받는 방식을 규격화하기 어렵고, 일반적으로 CPU와 메모리의 데이터 전송률은 높지만 입출력장치의 데이터 전송률이 낮다는 점이 있다.  

이런 이유로 I/O contoller, I/O module이라고도 하는 **장치 컨트롤러**가 나왔다. 장치 컨트롤러는 CPU와 입출력장치 간에 통신을 중개해주고, 오류 검출과 데이터 버퍼링 역할을 한다.

    버퍼링이란? 

    전송률이 높은 장치와 낮은 장치 사이에 주고받는 데이터를 버퍼라는 임시 저장 공간에 저장하여 전송률을 비슷하게 맞추는 방법이다.

장치 컨트롤러는 입출력 버스에 연결되고 데이터 레지스터, 상태 레지스터, 제어 레지스터를 갖는 구조이다. 상태 레지스터와 제어 레지스터는 하나의 레지스터로 사용되기도 한다.
- **데이터 레지스터**: CPU와 입출력장치 사이에 주고받을 데이터를 저장한다.
- **상태 레지스터**: 입출력장치가 준비가 되었는지, 작업이 완료되었는지, 오류는 없는지 등 상태 정보를 담는다.
- **제어 레지스터**: 입출력장치가 수행할 내용에 대한 제어 정보를 담는다.  

이 장치 컨트롤러의 동작을 감지하고 제어하는 프로그램이 **장치 드라이버**다. 장치 컨트롤러가 컴퓨터와 입출력장치 간의 하드웨어적인 통로라면 장치 드라이버는 소프트웨어적인 통로로 볼 수 있다.  

### 다양한 입출력 방식
1. **프로그램 입출력**
2. **인터럽트 기반 입출력**
3. **DMA 입출력**

#### 프로그램 입출력
프로그램 속 명령어로 장치 컨트롤러를 제어하는 방법이다.
메모리에 저장된 데이터를 하드디스크에 백업하는 예시를 통해 과정을 살펴보자. 이는 하드디스크에 새로운 정보를 쓰겠다는 말이다. CPU는 하드디스크 컨트롤러의 제어 레지스터에 쓰기 신호를 보낸다. 그럼 하드디스크 컨트롤러는 하드디스크의 상태를 확인하고 준비가 왼료됐다면 상태 레지스터에 준비 완료 신호를 보낸다. 상태를 확인한 CPU는 데이터 레지스터로 데이터를 보낸다.

> 여기서 CPU는 특정 장치 컨트롤러, 특정 레지스터를 어떻게 아는걸까?

그 방법은 아래와 같다.
- **메모리 맵 입출력**: 메모리에 접근하기 위한 주소 공간과 입출력장치에 접근하기 위한 주소 공간을 하나의 주소 공간으로 간주하는 방법이다. 1024만큼의 메모리 공간을 사용할 수 있는 컴퓨터가 있을 때, 0-511을 메모리 주소 공간, 512-1023을 입출력장치 주소 공간으로 사용하는 방법이다. 그래서 한 곳에 접근하기 위한 별도의 명령어가 필요 없다.
- **고립형 입출력**: 메모리를 위한 주소 공간과 입출력장치를 위한 주소 공간을 분리하는 방법이다. 0-1023 공간을 메모리를 위한 주소 공간으로 쓸 수도 있고 입출력장치를 위한 주소 공간으로도 쓸 수 있다. 이는 입출력 전용 명령어를 통해서 가능하다. 

#### 인터럽트 기반 입출력
하드웨어 인터럽트는 장치 컨트롤러에 의해 발생한다.CPU는 보통 모니터, 키보드, 마우스 등 여러 입출력장치로부터 동시다발적인 인터럽트를 받게 된다. 이때 플래그 레지스터 속 인터럽트 비트를 비활성화한채 인터럽트 발생 순서대로 서비스 루틴을 실행해 처리하는 방법이 있다. 하지만, 더 빨리 처리해야 하는 인터럽트가 있기 때문에 현실적으로 모든 인터럽트를 순차적으로 처리할 수 없다. 인터럽트 비트를 비활성화해도 가장 먼저 처리해야 하는 인터럽트(Non Maskable Inturrupt; NMI)가 발생한 경우와 인터럽트 비트를 활성화한 채 인터럽트를 처리하는 경우엔 서비스 루틴 A 실행 도중이라도 서비스 루틴 B를 실행하고 돌아오는 방법이 사용된다.  

이렇게 동시다발적인 인터럽트 상황에서 우선순위를 반영하기 위해 **PIC**(Programmable Interrupt Controller)라는 하드웨어를 사용한다. PIC는 여러 장치 컨트롤러에 연결되어 하드웨어 인터럽트 우선순위를 판단한 후, CPU에게 바로 처리해야할 인터럽트를 알려준다.

#### DMA(Direct Memory Access) 입출력
위의 프로그램 입출력, 인터럽트 기반 입출력 방식 모두 메모리와 입출력장치 간 데이터 이동을 CPU가 주도한다. CPU가 굉장히 많은 역할을 하고 있다는걸 알 수 있고, 그 부담을 덜기 위한 방법이 DMA 입출력 방식이다.  

DMA 입출력은 CPU를 거치지 않고 DMA 컨트롤러를 통해 입출력장치가 메모리에 직접적으로 접근하는 방식이다. DMA 컨트롤러가 CPU의 대행 역할을 한다고 볼 수 있다. DMA 컨트롤러가 시스템 버스를 사용하기 위해 CPU가 사용하지 않을 때 잠깐씩 쓰거나, CPU에게 일시적으로 자기가 사용하겠다는 허락을 구한다. 이를 **Cycle stealing**이라고도 한다.

> 근데 장치 컨트롤러가 시스템 버스에 직접적으로 연결되어도 괜찮을까?

시스템 버스는 공용 자원이기 때문에 어느 하나가 독점해 사용하면 결코 좋지 않다. 따라서 시스템 버스에 연결된 DMA 컨트롤러에 장치 컨트롤러들을 연결한 **입출력 버스**를 따로 놓아 시스템 버스의 이용 빈도를 낮춘다.